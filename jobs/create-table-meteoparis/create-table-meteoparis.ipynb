{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: this notebook was generated by dsflow*\n",
    "\n",
    "# create table meteoparis\n",
    "\n",
    "## \\[1- config\\] set input and output paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.20.0.3:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fa261afa438>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime as dt\n",
    "from pyspark.sql import SparkSession\n",
    "from dsflow_core.helpers import DsflowContext\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "dsflow = DsflowContext.create()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "default_task_specs = \"\"\"\n",
    "    {\"source_path\": \"/data/raw/meteoparis/ds=2017-11-24\",\n",
    "     \"sink_path\": \"/data/tables/meteoparis/ds=2017-11-24\",\n",
    "     \"ds\": \"2017-11-24\"}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source_path': '/data/raw/meteoparis/ds=2017-11-24', 'sink_path': '/data/tables/meteoparis/ds=2017-11-24', 'ds': '2017-11-24'}\n"
     ]
    }
   ],
   "source": [
    "task_specs_raw = os.environ.get('TASK_SPECS', default_task_specs)\n",
    "task_specs = json.loads(task_specs_raw)\n",
    "\n",
    "# dsflow alerts if something looks wrong\n",
    "dsflow.validade_task_specs(task_specs)\n",
    "\n",
    "print(task_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get task variables:\n",
    "source_path = task_specs[\"source_path\"]\n",
    "sink_path = task_specs[\"sink_path\"]\n",
    "ds = task_specs[\"ds\"]  # ds is the execution date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# https://public.opendatasoft.com/explore/dataset/donnees-synop-essentielles-omm/information/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\[2- first data check\\] using Spark, print a couple lines from source_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_data = spark.read.text(source_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|[{\"datasetid\": \"a...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\[3- process data\\] convert raw data into a Spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = (spark\n",
    ".read\n",
    ".json(source_path)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number of rows in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41551"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- datasetid: string (nullable = true)\n",
      " |-- fields: struct (nullable = true)\n",
      " |    |-- 2_metre_temperature: double (nullable = true)\n",
      " |    |-- forecast: string (nullable = true)\n",
      " |    |-- position: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |    |-- relative_humidity: double (nullable = true)\n",
      " |    |-- timestamp: string (nullable = true)\n",
      " |    |-- total_water_precipitation: double (nullable = true)\n",
      " |-- geometry: struct (nullable = true)\n",
      " |    |-- coordinates: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- record_timestamp: string (nullable = true)\n",
      " |-- recordid: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# by default, dataframe uses an auto-detected schema\n",
    "dataset.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset02 = dataset.selectExpr(\"fields.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing 10 random rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2_metre_temperature</th>\n",
       "      <th>forecast</th>\n",
       "      <th>position</th>\n",
       "      <th>relative_humidity</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>total_water_precipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.728647</td>\n",
       "      <td>2017-11-23T23:00:00+01:00</td>\n",
       "      <td>[49.15, 2.325]</td>\n",
       "      <td>95.755348</td>\n",
       "      <td>2017-11-23T19:00:00+01:00</td>\n",
       "      <td>0.336426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.078256</td>\n",
       "      <td>2017-11-23T23:00:00+01:00</td>\n",
       "      <td>[49.125, 2.1]</td>\n",
       "      <td>99.974098</td>\n",
       "      <td>2017-11-23T19:00:00+01:00</td>\n",
       "      <td>0.890137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.045053</td>\n",
       "      <td>2017-11-23T23:00:00+01:00</td>\n",
       "      <td>[49.125, 2.325]</td>\n",
       "      <td>98.317848</td>\n",
       "      <td>2017-11-23T19:00:00+01:00</td>\n",
       "      <td>0.662109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.044077</td>\n",
       "      <td>2017-11-23T23:00:00+01:00</td>\n",
       "      <td>[49.125, 2.575]</td>\n",
       "      <td>97.255348</td>\n",
       "      <td>2017-11-23T19:00:00+01:00</td>\n",
       "      <td>0.262695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.172006</td>\n",
       "      <td>2017-11-23T23:00:00+01:00</td>\n",
       "      <td>[49.1, 2.1]</td>\n",
       "      <td>100.005348</td>\n",
       "      <td>2017-11-23T19:00:00+01:00</td>\n",
       "      <td>1.161621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.572397</td>\n",
       "      <td>2017-11-23T23:00:00+01:00</td>\n",
       "      <td>[49.1, 2.325]</td>\n",
       "      <td>100.005348</td>\n",
       "      <td>2017-11-23T19:00:00+01:00</td>\n",
       "      <td>1.245117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.801889</td>\n",
       "      <td>2017-11-23T23:00:00+01:00</td>\n",
       "      <td>[49.1, 2.575]</td>\n",
       "      <td>96.692848</td>\n",
       "      <td>2017-11-23T19:00:00+01:00</td>\n",
       "      <td>0.760254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.678842</td>\n",
       "      <td>2017-11-23T23:00:00+01:00</td>\n",
       "      <td>[49.075, 2.075]</td>\n",
       "      <td>99.442848</td>\n",
       "      <td>2017-11-23T19:00:00+01:00</td>\n",
       "      <td>1.511719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.705209</td>\n",
       "      <td>2017-11-23T23:00:00+01:00</td>\n",
       "      <td>[49.075, 2.3]</td>\n",
       "      <td>98.755348</td>\n",
       "      <td>2017-11-23T19:00:00+01:00</td>\n",
       "      <td>2.009766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.211069</td>\n",
       "      <td>2017-11-23T23:00:00+01:00</td>\n",
       "      <td>[49.075, 2.575]</td>\n",
       "      <td>96.536598</td>\n",
       "      <td>2017-11-23T19:00:00+01:00</td>\n",
       "      <td>1.564453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   2_metre_temperature                   forecast         position  \\\n",
       "0             9.728647  2017-11-23T23:00:00+01:00   [49.15, 2.325]   \n",
       "1             9.078256  2017-11-23T23:00:00+01:00    [49.125, 2.1]   \n",
       "2            11.045053  2017-11-23T23:00:00+01:00  [49.125, 2.325]   \n",
       "3            11.044077  2017-11-23T23:00:00+01:00  [49.125, 2.575]   \n",
       "4             9.172006  2017-11-23T23:00:00+01:00      [49.1, 2.1]   \n",
       "5             9.572397  2017-11-23T23:00:00+01:00    [49.1, 2.325]   \n",
       "6            10.801889  2017-11-23T23:00:00+01:00    [49.1, 2.575]   \n",
       "7             9.678842  2017-11-23T23:00:00+01:00  [49.075, 2.075]   \n",
       "8            10.705209  2017-11-23T23:00:00+01:00    [49.075, 2.3]   \n",
       "9            10.211069  2017-11-23T23:00:00+01:00  [49.075, 2.575]   \n",
       "\n",
       "   relative_humidity                  timestamp  total_water_precipitation  \n",
       "0          95.755348  2017-11-23T19:00:00+01:00                   0.336426  \n",
       "1          99.974098  2017-11-23T19:00:00+01:00                   0.890137  \n",
       "2          98.317848  2017-11-23T19:00:00+01:00                   0.662109  \n",
       "3          97.255348  2017-11-23T19:00:00+01:00                   0.262695  \n",
       "4         100.005348  2017-11-23T19:00:00+01:00                   1.161621  \n",
       "5         100.005348  2017-11-23T19:00:00+01:00                   1.245117  \n",
       "6          96.692848  2017-11-23T19:00:00+01:00                   0.760254  \n",
       "7          99.442848  2017-11-23T19:00:00+01:00                   1.511719  \n",
       "8          98.755348  2017-11-23T19:00:00+01:00                   2.009766  \n",
       "9          96.536598  2017-11-23T19:00:00+01:00                   1.564453  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsflow.display(dataset02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing 10 random rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>datasetid</th>\n",
       "      <th>record_timestamp</th>\n",
       "      <th>recordid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>41551</td>\n",
       "      <td>41551</td>\n",
       "      <td>41551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>arome-0025-sp1_sp2_paris</td>\n",
       "      <td>2017-11-23T19:00:00+01:00</td>\n",
       "      <td>arome_0025_sp1_sp2_lastgrib2/10233181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>arome-0025-sp1_sp2_paris</td>\n",
       "      <td>2017-11-23T19:00:00+01:00</td>\n",
       "      <td>arome_0025_sp1_sp2_lastgrib2/9775023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary                 datasetid           record_timestamp  \\\n",
       "0   count                     41551                      41551   \n",
       "1    mean                      None                       None   \n",
       "2  stddev                      None                       None   \n",
       "3     min  arome-0025-sp1_sp2_paris  2017-11-23T19:00:00+01:00   \n",
       "4     max  arome-0025-sp1_sp2_paris  2017-11-23T19:00:00+01:00   \n",
       "\n",
       "                                recordid  \n",
       "0                                  41551  \n",
       "1                                   None  \n",
       "2                                   None  \n",
       "3  arome_0025_sp1_sp2_lastgrib2/10233181  \n",
       "4   arome_0025_sp1_sp2_lastgrib2/9775023  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsflow.display(dataset.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\[4- write on disk\\] write the output as parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_dataset = dataset02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(final_dataset\n",
    " .write\n",
    " .mode(\"overwrite\")\n",
    " .parquet(sink_path)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'not implemented'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsflow.validade_task_output(task_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
